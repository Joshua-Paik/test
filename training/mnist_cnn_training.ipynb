{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST CNN Training for TensorFlow.js\n",
    "\n",
    "This notebook trains a Convolutional Neural Network (CNN) on the MNIST dataset and converts it to TensorFlow.js format for use in the web application.\n",
    "\n",
    "## Overview\n",
    "- Load and preprocess MNIST data\n",
    "- Build a CNN architecture optimized for digit recognition\n",
    "- Train the model with data augmentation\n",
    "- Evaluate performance\n",
    "- Convert to TensorFlow.js format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflowjs as tfjs\n",
    "import os\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess MNIST Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print(f\"Training data shape: {x_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Test data shape: {x_test.shape}\")\n",
    "print(f\"Test labels shape: {y_test.shape}\")\n",
    "\n",
    "# Normalize pixel values to [0, 1] range\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Reshape data to add channel dimension (28, 28, 1)\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(f\"Preprocessed training data shape: {x_train.shape}\")\n",
    "print(f\"Preprocessed training labels shape: {y_train.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some sample images\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(x_train[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'Label: {np.argmax(y_train[i])}')\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Sample MNIST Images')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build CNN Architecture\n",
    "\n",
    "We'll create a lightweight CNN that's optimized for web deployment while maintaining good accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model():\n",
    "    \"\"\"\n",
    "    Create a CNN model optimized for MNIST digit recognition and web deployment.\n",
    "    \n",
    "    Architecture:\n",
    "    - 2 Convolutional blocks with MaxPooling\n",
    "    - Dropout for regularization\n",
    "    - Dense layers for classification\n",
    "    - Optimized for small size and fast inference\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        # First convolutional block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Second convolutional block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Flatten and dense layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10, activation='softmax')  # 10 classes for digits 0-9\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_cnn_model()\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Create data augmentation for better generalization\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks for training\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=2,\n",
    "        min_lr=0.0001\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "history = model.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size=128),\n",
    "    steps_per_epoch=len(x_train) // 128,\n",
    "    epochs=15,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate Model Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions on sample images\n",
    "predictions = model.predict(x_test[:10])\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(y_test[:10], axis=1)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'True: {true_classes[i]}, Pred: {predicted_classes[i]}')\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Sample Predictions')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print confidence scores\n",
    "print(\"Prediction confidence scores:\")\n",
    "for i in range(10):\n",
    "    confidence = np.max(predictions[i])\n",
    "    print(f\"Image {i}: Predicted {predicted_classes[i]} with {confidence:.3f} confidence\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Convert Model to TensorFlow.js Format\n",
    "\n",
    "This step converts the trained model to a format that can be used in the web browser.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for the TensorFlow.js model\n",
    "model_dir = './tfjs_model'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Convert and save the model in TensorFlow.js format\n",
    "print(\"Converting model to TensorFlow.js format...\")\n",
    "tfjs.converters.save_keras_model(model, model_dir)\n",
    "print(f\"Model saved to {model_dir}\")\n",
    "\n",
    "# Display model file information\n",
    "import os\n",
    "print(\"\\nGenerated files:\")\n",
    "for file in os.listdir(model_dir):\n",
    "    file_path = os.path.join(model_dir, file)\n",
    "    size = os.path.getsize(file_path)\n",
    "    print(f\"  {file}: {size:,} bytes\")\n",
    "\n",
    "print(f\"\\nTotal model size: {sum(os.path.getsize(os.path.join(model_dir, f)) for f in os.listdir(model_dir)):,} bytes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Model with Canvas-like Input\n",
    "\n",
    "Let's test how the model performs with images similar to what users will draw on the canvas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_canvas_image(image_array):\n",
    "    \"\"\"\n",
    "    Preprocess an image array to match the model's expected input format.\n",
    "    This simulates the preprocessing that will happen in the web app.\n",
    "    \"\"\"\n",
    "    # Ensure the image is 28x28\n",
    "    if image_array.shape != (28, 28):\n",
    "        # In the web app, we'll resize the canvas drawing to 28x28\n",
    "        pass\n",
    "    \n",
    "    # Normalize to [0, 1] range\n",
    "    image_array = image_array.astype('float32') / 255.0\n",
    "    \n",
    "    # Add batch and channel dimensions\n",
    "    image_array = image_array.reshape(1, 28, 28, 1)\n",
    "    \n",
    "    return image_array\n",
    "\n",
    "# Test with a sample image\n",
    "test_image = x_test[0].reshape(28, 28) * 255  # Convert back to 0-255 range\n",
    "processed_image = preprocess_canvas_image(test_image)\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.predict(processed_image, verbose=0)\n",
    "predicted_digit = np.argmax(prediction)\n",
    "confidence = np.max(prediction)\n",
    "\n",
    "print(f\"Predicted digit: {predicted_digit}\")\n",
    "print(f\"Confidence: {confidence:.4f}\")\n",
    "print(f\"All probabilities: {prediction[0]}\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_image, cmap='gray')\n",
    "plt.title(f'Input Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(range(10), prediction[0])\n",
    "plt.title(f'Prediction Probabilities')\n",
    "plt.xlabel('Digit')\n",
    "plt.ylabel('Probability')\n",
    "plt.xticks(range(10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save the Model\n",
    "\n",
    "Save the trained model in multiple formats for backup and future use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in native Keras format (.keras)\n",
    "model_path = './mnist_cnn_model.keras'\n",
    "model.save(model_path)\n",
    "print(f\"Model saved as {model_path}\")\n",
    "\n",
    "# Save model architecture as JSON (optional)\n",
    "model_json = model.to_json()\n",
    "with open('./mnist_cnn_architecture.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "print(\"Model architecture saved as mnist_cnn_architecture.json\")\n",
    "\n",
    "# Save model weights separately (HDF5 requires filename ending with `.weights.h5`)\n",
    "model.save_weights('./mnist_cnn_model.weights.h5')\n",
    "print(\"Model weights saved as mnist_cnn_model.weights.h5\")\n",
    "\n",
    "# Save training history\n",
    "import pickle\n",
    "with open('./training_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "print(\"Training history saved as training_history.pkl\")\n",
    "\n",
    "# Print summary of saved files\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING COMPLETE - FILES SAVED:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"✓ TensorFlow.js model: ./tfjs_model/\")\n",
    "print(f\"✓ Keras model: {model_path}\")\n",
    "print(f\"✓ Model architecture: ./mnist_cnn_architecture.json\")\n",
    "print(f\"✓ Model weights: ./mnist_cnn_weights.h5\")\n",
    "print(f\"✓ Training history: ./training_history.pkl\")\n",
    "print(f\"✓ Final test accuracy: {test_accuracy:.4f}\")\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
